# -*- coding: utf-8 -*-
# Home.py â€” í•´ì–‘ ìƒë¬¼ë‹¤ì–‘ì„± ë¦¬ìŠ¤í¬ ëŒ€ì‹œë³´ë“œ (ìš”ì•½/í•˜ì´ë¼ì´íŠ¸/ë¹ ë¥¸ ì´ë™)

from pathlib import Path
import pandas as pd
import numpy as np
import streamlit as st
import altair as alt

st.set_page_config(
    page_title="HRA ëŒ€ì‹œë³´ë“œ â€” Home",
    page_icon="ğŸ ",
    layout="wide",
    initial_sidebar_state="expanded",
)

alt.data_transformers.disable_max_rows()

# -----------------------------
# ê²½ë¡œ/ë¡œë”/ìŠ¤í‚¤ë§ˆ ë³´ì •
# -----------------------------
DATA_FILES = {
    "rreal": "rreal_final_ALL_predicted.csv",
    "label_total": "hra_label_total_2025_2028.csv",
    "pairwise": "hra_pairwise_2025_2028.csv",
}

def find_data_path(filename: str):
    cands = [
        Path.cwd() / "data" / filename,
        Path(__file__).parent / "data" / filename,
        Path.cwd() / filename,
        Path(__file__).parent / filename,
        Path("/mnt/data") / filename,
    ]
    for p in cands:
        if p.exists():
            return p
    return None

@st.cache_data(show_spinner=False)
def load_csv(name_key: str) -> pd.DataFrame:
    fn = DATA_FILES[name_key]
    p = find_data_path(fn)
    if p is None:
        raise FileNotFoundError(f"ë°ì´í„° íŒŒì¼ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤: {fn}")
    for enc in ("utf-8-sig", "utf-8", "cp949"):
        try:
            return pd.read_csv(p, encoding=enc)
        except Exception:
            continue
    return pd.read_csv(p)

def _coerce_year_month(s: pd.Series) -> pd.Series:
    s2 = pd.to_datetime(s, errors="coerce", infer_datetime_format=True)
    if s2.isna().mean() > 0.9:
        ss = s.astype(str).str.replace(r"[^0-9]", "", regex=True)
        mask6 = ss.str.len() == 6
        ss.loc[mask6] = ss[mask6] + "01"
        s2 = pd.to_datetime(ss, errors="coerce", format="%Y%m%d")
    return s2.dt.to_period("M").dt.to_timestamp(how="start")

def soft_fix(df: pd.DataFrame):
    r_like = [c for c in df.columns if str(c).lower() in ("region", "ì§€ì—­")]
    if r_like: df = df.rename(columns={r_like[0]: "region"})
    if "year_month" in df.columns:
        df = df.copy(); df["year_month"] = _coerce_year_month(df["year_month"])
    else:
        lower = {str(c).lower(): c for c in df.columns}
        for k in ("ym", "date", "dt", "yearmonth", "ì›”", "ë‚ ì§œ"):
            if k in lower:
                df = df.copy(); df["year_month"] = _coerce_year_month(df[lower[k]])
                break
    return df

# -----------------------------
# ë°ì´í„° ë¡œë“œ
# -----------------------------
load_errors = []
try:
    df_label = soft_fix(load_csv("label_total"))
except Exception as e:
    df_label = pd.DataFrame(); load_errors.append(("hra_label_total_2025_2028.csv", str(e)))

try:
    df_pw = soft_fix(load_csv("pairwise"))
except Exception as e:
    df_pw = pd.DataFrame(); load_errors.append(("hra_pairwise_2025_2028.csv", str(e)))

# -----------------------------
# í—¤ë”
# -----------------------------
st.title("ğŸŒŠ í•´ì–‘ ìƒë¬¼ë‹¤ì–‘ì„± ë¦¬ìŠ¤í¬ ëŒ€ì‹œë³´ë“œ")
st.caption("ì™¼ìª½ ì‚¬ì´ë“œë°”ì—ì„œ í˜ì´ì§€ë¥¼ ì´ë™í•  ìˆ˜ ìˆì–´ìš”. ì•„ë˜ì—ì„œ ìµœê·¼ ìœ„í—˜ë„ í•˜ì´ë¼ì´íŠ¸ë¥¼ ë¹ ë¥´ê²Œ í™•ì¸í•˜ì„¸ìš”.")

if load_errors:
    with st.expander("âš ï¸ ë°ì´í„° ë¡œë“œ ì˜¤ë¥˜(í¼ì³ë³´ê¸°)"):
        for fn, msg in load_errors:
            st.write(f"**{fn}**"); st.code(msg)

if df_label.empty:
    st.error("`hra_label_total_2025_2028.csv` ë¥¼ ë¶ˆëŸ¬ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. data/ í´ë”ë¥¼ í™•ì¸í•˜ì„¸ìš”.")
    st.stop()

# risk_level í‘œì¤€í™” (ì—†ìœ¼ë©´ label_sum â†’ ì´ë¦„)
if "risk_level" in df_label.columns:
    df_label["risk_name"] = df_label["risk_level"].astype(str).str.strip().str.title()
else:
    df_label["risk_name"] = (
        df_label.get("label_sum", pd.Series(index=df_label.index))
                .map({1: "Low", 2: "Medium", 3: "High"})
                .fillna("Unknown")
    )

ORDER = ["Low", "Medium", "High"]
COLOR = {"Low": "#4CAF50", "Medium": "#FFC107", "High": "#F44336"}
df_label["risk_name"] = pd.Categorical(df_label["risk_name"], categories=ORDER, ordered=True)

# -----------------------------
# KPI ì¹´ë“œ
# -----------------------------
regions = sorted(df_label["region"].dropna().unique().tolist()) if "region" in df_label.columns else []
first_dt = df_label["year_month"].min() if "year_month" in df_label.columns else None
last_dt  = df_label["year_month"].max() if "year_month" in df_label.columns else None

c1, c2, c3, c4 = st.columns(4)
c1.metric("ğŸ“ ì§€ì—­ ìˆ˜", f"{len(regions):,}")
c2.metric("ğŸ§¾ ì „ì²´ ë ˆì½”ë“œ", f"{len(df_label):,}")
c3.metric("â±ï¸ ê¸°ê°„ ì‹œì‘", first_dt.strftime("%Y-%m") if pd.notna(first_dt) else "-")
c4.metric("â±ï¸ ê¸°ê°„ ì¢…ë£Œ", last_dt.strftime("%Y-%m") if pd.notna(last_dt) else "-")

st.divider()

# -----------------------------
# ì—°/ì›” ì„ íƒ â†’ ì´ë²ˆ ë‹¬ ìš”ì•½
# -----------------------------
years = sorted(df_label["year_month"].dt.year.unique().tolist())
default_year = max(years) if years else 2025
months_avail = sorted(df_label.loc[df_label["year_month"].dt.year.eq(default_year), "year_month"]
                      .dt.month.unique().tolist())

colY, colM = st.columns([1, 1])
sel_year = colY.selectbox("ì—°ë„ ì„ íƒ", years, index=years.index(default_year) if years else 0)
m_labels = [f"{m:02d}" for m in months_avail]
default_mm = f"{max(months_avail):02d}" if months_avail else "01"
sel_month = int(colM.selectbox("ì›” ì„ íƒ", m_labels, index=m_labels.index(default_mm) if m_labels else 0))

sel_stamp = pd.Timestamp(f"{sel_year}-{sel_month:02d}-01")
st.caption(f"ì„ íƒ ì›”: **{sel_year}_{sel_month:02d}**")
df_m = df_label[df_label["year_month"].eq(sel_stamp)].copy()

# ë¶„í¬(ì „ì²´/ì§€ì—­ë³„)
lcol, rcol = st.columns([1.1, 1.3])

with lcol:
    st.subheader("ì´ë²ˆ ë‹¬ ìœ„í—˜ë„ ë¶„í¬")
    dist = (df_m["risk_name"].value_counts()
                      .reindex(ORDER).fillna(0)
                      .rename_axis("risk_name").reset_index(name="count"))
    chart = (alt.Chart(dist).mark_bar().encode(
        x=alt.X("risk_name:N", title="risk level", sort=ORDER),
        y=alt.Y("count:Q", title="ê±´ìˆ˜"),
        color=alt.Color("risk_name:N",
                        scale=alt.Scale(domain=ORDER, range=[COLOR[k] for k in ORDER]),
                        legend=alt.Legend(title="risk level")),
        tooltip=[alt.Tooltip("risk_name:N", title="risk level"),
                 alt.Tooltip("count:Q", title="ê±´ìˆ˜", format=",")],
    ).properties(height=300))
    st.altair_chart(chart, use_container_width=True)

with rcol:
    st.subheader("ì§€ì—­ë³„ ìœ„í—˜ë„ ë¶„í¬(ìŠ¤íƒ)")
    rc = (df_m.groupby(["region", "risk_name"], dropna=False)
               .size().reset_index(name="count"))
    stacked = (alt.Chart(rc).mark_bar().encode(
        x=alt.X("region:N", title="ì§€ì—­"),
        y=alt.Y("count:Q", stack="zero", title="ê±´ìˆ˜"),
        color=alt.Color("risk_name:N",
                        scale=alt.Scale(domain=ORDER, range=[COLOR[k] for k in ORDER]),
                        legend=alt.Legend(title="risk level")),
        tooltip=[alt.Tooltip("region:N", title="ì§€ì—­"),
                 alt.Tooltip("risk_name:N", title="risk level"),
                 alt.Tooltip("count:Q", title="ê±´ìˆ˜", format=",")],
    ).properties(height=300))
    st.altair_chart(stacked, use_container_width=True)

st.divider()

# -----------------------------
# High ì§€ì—­ í•˜ì´ë¼ì´íŠ¸ + pairwise Top-1 ìŠ¤íŠ¸ë ˆìŠ¤
# -----------------------------
st.subheader("ğŸ” High ì§€ì—­ í•˜ì´ë¼ì´íŠ¸ (ì„ íƒ ì›”)")
high_regions = df_m.loc[df_m["risk_name"] == "High", "region"].dropna().unique().tolist()
if not high_regions:
    st.info("ì„ íƒí•œ ì—°/ì›”ì—ëŠ” **High**ë¡œ ë¶„ë¥˜ëœ ì§€ì—­ì´ ì—†ìŠµë‹ˆë‹¤.")
else:
    if df_pw.empty or not set(["region", "year_month"]).issubset(df_pw.columns):
        st.warning("pairwise ë°ì´í„°ê°€ ì—†ê±°ë‚˜ ìŠ¤í‚¤ë§ˆê°€ ë§ì§€ ì•Šì•„ ìŠ¤íŠ¸ë ˆìŠ¤ ìš”ì¸ì„ ë³¼ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    else:
        dfp = df_pw.copy()
        if "stressor" not in dfp.columns:
            s_col = next((c for c in dfp.columns if "stress" in c.lower()), None)
            if s_col: dfp = dfp.rename(columns={s_col: "stressor"})
        r_col = next((c for c in dfp.columns if str(c).lower() in ("r", "risk")), None)
        if r_col and r_col != "R": dfp = dfp.rename(columns={r_col: "R"})

        dfp = dfp[(dfp["year_month"] == sel_stamp) & (dfp["region"].isin(high_regions))].copy()
        if dfp.empty or ("stressor" not in dfp.columns) or ("R" not in dfp.columns):
            st.info("ì„ íƒí•œ ì›”ì˜ pairwise ë ˆì½”ë“œê°€ ì—†ê±°ë‚˜ í•„ìˆ˜ ì»¬ëŸ¼(stressor/R)ì´ ì—†ìŠµë‹ˆë‹¤.")
        else:
            g = (dfp.groupby(["region", "stressor"], as_index=False)["R"]
                    .mean().rename(columns={"R": "R_mean"}))
            top1 = (g.sort_values(["region", "R_mean"], ascending=[True, False])
                      .groupby("region", as_index=False).head(1))
            top1["R_mean"] = top1["R_mean"].round(3)
            st.dataframe(
                top1.rename(columns={"region":"ì§€ì—­","stressor":"ìµœëŒ€ R ìš”ì¸","R_mean":"Rê°’(í‰ê· )"}),
                use_container_width=True
            )

st.divider()

# -----------------------------
# ë¹ ë¥¸ ì´ë™
# -----------------------------
st.subheader("âš¡ ë¹ ë¥¸ ì´ë™")
col1, col2 = st.columns(2)
with col1:
    if hasattr(st, "page_link"):
        st.page_link("pages/01_Data.py", label="ğŸ“¦ Data (Integrated / risk_total / risk_stress)")
    else:
        st.markdown("ğŸ“¦ **Data** í˜ì´ì§€ëŠ” ì‚¬ì´ë“œë°”ì—ì„œ **Data**ë¥¼ í´ë¦­í•˜ì„¸ìš”.")
with col2:
    if hasattr(st, "page_link"):
        st.page_link("pages/02_Risk.py", label="ğŸ—ºï¸ Risk map (ì›”ë³„ ì§€ë„)")
    else:
        st.markdown("ğŸ—ºï¸ **Risk map** í˜ì´ì§€ëŠ” ì‚¬ì´ë“œë°”ì—ì„œ **risk map**ì„ í´ë¦­í•˜ì„¸ìš”.")